"""Module for testing Mean-Variance Optimization (MVO) model functionality.

This module contains tests for the MVO model components of the project,
including target generation and model optimization. It verifies that the
model produces expected allocations, portfolio values, and risk metrics.
"""

from datetime import timedelta

import pandas as pd
import pytest

from ifunnel.models.MVOmodel import mvo_model
from ifunnel.models.MVOtargets import get_mvo_targets


@pytest.fixture(scope="module")
def mvo_target_data(start_test_date, weekly_returns, request):
    """Generate MVO targets and benchmark portfolio values for testing.

    This fixture calls the get_mvo_targets function with the specified benchmark
    (provided via parametrization) to generate volatility targets and benchmark
    portfolio values for testing the MVO model.

    Args:
        start_test_date: Start date for the test dataset.
        weekly_returns: DataFrame containing weekly returns data.
        request: Pytest request object for accessing parametrized values.

    Returns:
        tuple: A tuple containing:
            - targets: DataFrame with volatility targets.
            - benchmark_port_val: DataFrame with benchmark portfolio values.
    """
    start_of_test_dataset = str(start_test_date + timedelta(days=1))
    targets, benchmark_port_val = get_mvo_targets(
        test_date=start_of_test_dataset,
        benchmark=request.getfixturevalue(request.param),  # MSCI World benchmark
        budget=100,
        data=weekly_returns,
    )
    return targets, benchmark_port_val


@pytest.mark.parametrize(
    "mvo_target_data, label",
    [("benchmark_isin_1", "1"), ("benchmark_isin_2", "2")],
    indirect=["mvo_target_data"],
)
def test_get_mvo_targets(mvo_target_data, label, resource_dir):
    """Test the MVO target generation functionality.

    This test verifies that the volatility targets and benchmark portfolio values
    generated by the get_mvo_targets function match the expected baseline values.
    The test is parametrized to run with different benchmark portfolios.

    Args:
        mvo_target_data: Fixture providing the generated targets and benchmark values.
        label: Label identifying the benchmark portfolio being tested.
        resource_dir: Path to the directory containing test resources.
    """
    expected_targets = pd.read_csv(resource_dir / f"mvo/targets_{label}_BASE.csv", index_col=0)
    expected_benchmark_port_val = pd.read_csv(
        resource_dir / f"mvo/benchmark_port_val_{label}_BASE.csv",
        index_col=0,
        parse_dates=True,
    )
    expected_benchmark_port_val.index = expected_benchmark_port_val.index.astype("datetime64[us]")

    targets, benchmark_port_val = mvo_target_data

    # targets.to_csv(f"tests/mvo/targets_{label}_ACTUAL.csv")
    # benchmark_port_val.to_csv(f"tests/mvo/benchmark_port_val_{label}_ACTUAL.csv")
    pd.testing.assert_frame_equal(targets, expected_targets)
    pd.testing.assert_frame_equal(benchmark_port_val, expected_benchmark_port_val)


@pytest.mark.parametrize("mvo_target_data", ["benchmark_isin_2"], indirect=True)
def test_mvo_model(test_narrow_dataset, moments, mvo_target_data, resource_dir):
    """Test the MVO model optimization functionality.

    This test verifies that the MVO model produces the expected portfolio allocations,
    values, and risk metrics when run with the CLARABEL solver. It compares the model
    outputs against baseline files and checks that active constraints are satisfied.

    Args:
        test_narrow_dataset: DataFrame containing test return data.
        moments: Tuple containing (sigma_list, mu_list) for the optimization.
        mvo_target_data: Fixture providing volatility targets and benchmark values.
        resource_dir: Path to the directory containing test resources.
    """
    expected_port_allocation = pd.read_csv(resource_dir / "mvo/port_allocation_CLARABEL.csv", index_col=0)
    expected_port_value = pd.read_csv(resource_dir / "mvo/port_value_CLARABEL.csv", index_col=0, parse_dates=True)
    expected_port_risk = pd.read_csv(resource_dir / "mvo/port_risk_CLARABEL.csv", index_col=0)

    targets, _ = mvo_target_data
    sigma_lst, mu_lst = moments

    port_allocation, port_value, port_risk = mvo_model(
        mu_lst=mu_lst,
        sigma_lst=sigma_lst,
        test_ret=test_narrow_dataset,
        targets=targets,  # Target
        budget=100,
        trans_cost=0.001,
        max_weight=1,
        solver="CLARABEL",
        lower_bound=0,
    )

    # Uncomment to generate new baseline files with CLARABEL solver
    # port_allocation.to_csv(resource_dir / "mvo/port_allocation_CLARABEL.csv")
    # port_value.to_csv(resource_dir / "mvo/port_value_CLARABEL.csv")
    # port_risk.to_csv(resource_dir / "mvo/port_risk_CLARABEL.csv")

    active_constraints = (targets.to_numpy() - port_risk.to_numpy()) < 1e-5

    # Ensure both DataFrames have the same columns in the same order
    all_columns = sorted(set(port_allocation.columns) | set(expected_port_allocation.columns))
    port_allocation = port_allocation.reindex(columns=all_columns).fillna(0)
    expected_port_allocation = expected_port_allocation.reindex(columns=all_columns).fillna(0)

    # Ensure both DataFrames have the same indices for port_value
    port_value = port_value.reindex(expected_port_value.index)

    # Ensure both DataFrames have the same indices for port_risk
    port_risk_active = port_risk[active_constraints].reindex(expected_port_risk[active_constraints].index)
    expected_port_risk_active = expected_port_risk[active_constraints]

    pd.testing.assert_frame_equal(port_allocation, expected_port_allocation, atol=1e-5)
    pd.testing.assert_frame_equal(port_value, expected_port_value)
    pd.testing.assert_frame_equal(port_risk_active, expected_port_risk_active)
